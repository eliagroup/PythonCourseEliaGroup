{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<img src=\"./image/Logo/logo_elia_group.png\" width = 200>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Joining\n",
    "<br> \n",
    "\n",
    "Sometimes, it might be nesesary to **combine** several data sets. To do so, you need to have a common feature in each data set to join/merge data from various sources.  \n",
    "Let's look at different methods on how your data can be joined together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='./image/inner_join.png' width = 300></td><td><img src='./image/outer_join.png' width = 300></td></tr></table>\n",
    "<table><tr><td><img src='./image/left_join.png' width = 300></td><td><img src='./image/right_join.png' width = 300></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "In order to understand all these methods, take a look at the examples below and try to figure out how this **data joining** works.\n",
    "\n",
    "*Hint: The key column on which you are merging the DataFrames is column `C`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "<center><img src=\"./image/inner_join_example.png\" width = 800/></center>\n",
    "\n",
    "</br>\n",
    "<center><img src=\"./image/outer_join_example.png\" width = 800/></center>\n",
    "\n",
    "</br>\n",
    "<center><img src=\"./image/left_join_example.png\" width = 800 /></center>\n",
    "\n",
    "</br>\n",
    "<center><img src=\"./image/right_join_example.png\" width = 800 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge - First Steps\n",
    "\n",
    "Now it's your turn! üöÄ\n",
    "<br>\n",
    "\n",
    "Let's upload two data sets from [Elia Open Data API](https://www.elia.be/en/grid-data/open-data). The first data set describes the measured and upscaled **total load on the Belgian grid** and presents data from 1st Jan 2019 **until 31th Jan 2019**, whereas the second one describes the measured and upscaled **load on the Elia grid** from 1st Jan 2019 until **only the 15th Jan 2019**. <br>\n",
    "\n",
    "1. Read in the two data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "total_load = pd.read_csv(\"./data/energy/total_load_2019_01.csv\", sep = \";\", parse_dates = True)\n",
    "elia_load = pd.read_csv(\"./data/energy/elia_load_2019_01_15.csv\", sep = \";\", parse_dates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Take a quick look at them so you know with what your are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the total load on the Belgian grid from 1. to 31.01.2019: \")\n",
    "print(total_load.head())\n",
    "print(\"(Rows, Columns): \", total_load.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the load on the Elia grid from 1. to 15.01.2019: \")\n",
    "print(elia_load.head())\n",
    "print(\"(Rows, Columns): \", elia_load.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to merge both data frames, you need to rename one of the Datetime columns, since their content is the same but their column is named differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_load = elia_load.rename(columns={\"Datetime\": \"DateTime\"})\n",
    "elia_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(total_load, elia_load)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì**Question**: Look at the new merged DataFrame - can you guess which kind of merge method was used? Since we did not specify any parameters within the merge function, this method is the default!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_merged = pd.merge(total_load, elia_load, how = \"outer\")\n",
    "df2_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional parameters of merge\n",
    "\n",
    "Obviously, you can do way more then just \"inner\" or \"outer\" merging. There are lots of parameters with which you can specify things like merging method or add suffixes. Find out all about the different parameters in merge [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html). \n",
    "<br>\n",
    "\n",
    "Let's check out some of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_merged = total_load.merge(elia_load, on = \"DateTime\", how = \"left\", suffixes=(\"_total\", \"_elia\"))\n",
    "\n",
    "df3_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you remember how we previously renamed the `datetime` column of the `elia_load` DataFrame in order to merge it afterwards? You actually don't need to do that. Instead, you can use the merge parameters **left_on** and **right_on**. To do so, let's re-import the data, but store it into another variable called `elia_load_2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_load_2 = pd.read_csv(\"./data/energy/elia_load_2019_01_15.csv\", sep = \";\", parse_dates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the column names of your two dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elia_load_2.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_load.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the columns with date & time in both DataFrames are basically the same, **BUT** named differently. To still be able to merge these two DataFrames based **on** the column containing date & time, you can use the parameters **\"left_on\"** and **\"right_on\"** in the merge function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_merged = elia_load_2.merge(total_load, left_on = \"Datetime\", right_on = \"DateTime\", suffixes=(\"_total\", \"_elia\"))\n",
    "\n",
    "df4_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128526; Cool, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Now it's your turn! \n",
    "\n",
    "Given the following two DataFrames `df1_job` and `df2_hired`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_job = pd.DataFrame({'employee': ['Bob', 'Jake', 'Ahmed', 'Sue'],\n",
    "                    'group': ['Data Science', 'Data Engineering', 'Data Engineering', 'Data Analyst']})\n",
    "df2_hired = pd.DataFrame({'employee': ['Ahmed', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2006, 2008, 2014, 2021]})\n",
    "print(\"df1_job:\\n\",df1_job)\n",
    "print(\"df2_hired:\\n\",df2_hired)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print out the **first three rows of each DataFrame** before merging\n",
    "- Merge the DataFrames based on the **employees' names** and save it into a new DataFrame called `df_job_hired`\n",
    "- Print out the **first 3 rows** of `df_job_hired`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete this line and replace it with your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Exercise\n",
    "\n",
    "In the DataFrame `df2_hired` somebody changed the name of the employee column. In addition, a column called `responsibility` was added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_job = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                       'group': ['Data Science', 'Data Engineering', 'Data Engineering', 'Data Analyst'],\n",
    "                    'responsibility': [\"Energy Forecast\", \"Data pipelines\", \"Data pipelines\", \"Interpreting Results\"]})\n",
    "\n",
    "df2_hired = pd.DataFrame({'employee_names': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                         'hire_date': [2004, 2008, 2012, 2014],\n",
    "                         'responsibility': [\"yes\", \"no\", \"no\", \"yes\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See if both `responsibility` columns represent the same values and can be merged into one column\n",
    "- Merge the two DataFrames, save them in a new variable called `df_job_hired_2`\n",
    "- Add suffixes (\"_job\", \"_hired\") so you can still distinguish the columns after merging\n",
    "- Finally, print out `df_job_hired_2`\n",
    "\n",
    "&#128161; <ins>Hint</ins>: Use the parameters **left_on**, **right_on** of the `.merge()` function. And don't forget, you can always check the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete this line and replace it with your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating two DataFrames\n",
    "<br>\n",
    "\n",
    "You can also stitch two or more DataFrames together with `.concat()`. Let's get right to it!\n",
    "<br>\n",
    "\n",
    "For the following example, you need to import three new data sets. They all describe the physical energy flows on the interconnections between the Belgian bidding zone and the neighbouring bidding zones. A positive figure means export from Belgium, while a negative figure means import into Belgium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morning = pd.read_csv(\"data/energy/PhysicalFlow_0-8.csv\", index_col=0)\n",
    "df_noon = pd.read_csv(\"data/energy/PhysicalFlow_8-16.csv\", index_col=0)\n",
    "df_evening = pd.read_csv(\"data/energy/PhysicalFlow_16-24.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at each of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_morning.head(n=3) # includes data from 0-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noon.head(n=3) # includes data from 8-16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evening.head(n=3) # includes data from 16-24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your new data sets is the follwing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(rows, columns) of the morning DataFrame: \" + str(df_morning.shape))\n",
    "print(\"(rows, columns) of the noon DataFrame: \" + str(df_noon.shape))\n",
    "print(\"(rows, columns) of the evening DataFrame: \" + str(df_evening.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128077; Nice! ... Maybe you have already discovered that the data sets are from the same day - but at different times of that day. So let's put them together with the new function `.concat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_morning, df_noon, df_evening ]).sort_values(\"Datetime\").reset_index(drop=True)\n",
    "print(\"(rows, columns) of df_concat: \" + str(df_concat.shape))\n",
    "df_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional parameters in concat()\n",
    "<br> \n",
    "\n",
    "As always, there are many more things you can do with `concat()`. [See for yourself](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) or use the help function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(pd.concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redo the last example and verify integrity, which means, checking for duplicates in the three DataFrames: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_morning, df_noon, df_evening], verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might wonder, why \"nothing has happend\". Well, let's create a DataFrame **WITH** duplicates.\n",
    "<br>\n",
    "The following data set also includes morning daytimes from 0 until 9 but that overlaps with the `df_noon` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates = pd.read_csv(\"data/energy/PhysicalFlow_0-9.csv\", index_col = 0)\n",
    "\n",
    "df_duplicates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now concatenate them and check for duplicates, an error message will appear: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_dupl = pd.concat([df_duplicates, df_noon, df_evening], verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now get an error message for `df_concat_dupl` because there are duplicates within the DataFrames we intended to concat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "In the following, two dataframes (`dp1_df`, and `dp2_df`) are given. They both describe a number of employees working on a data related project together. They share the same column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp1_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR', 'Location': 'State Street'},\n",
    "                         {'Name': 'Sally', 'Role': 'Data Scientist', 'Location': 'Washington Avenue'},\n",
    "                         {'Name': 'James', 'Role': 'Data Engineer', 'Location': 'Washington Avenue'}])\n",
    "dp2_df = pd.DataFrame([{'Name': 'James', 'Role': 'Analyst', 'Location': '1024 Billiard Avenue'},\n",
    "                           {'Name': 'Mike', 'Role': 'Regulations', 'Location': 'Fraternity House #22'},\n",
    "                           {'Name': 'Sally', 'Role': 'MlOps', 'Location': '512 Wilson Crescent'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concatenate the DataFrames and save them in a new DataFrame called `data_project_df`\n",
    "- When you concatenated the DataFrames, have a look at the index (*Hint: it is not continuous*)\n",
    "- Add the parameter \"ignore_index = True\" to create a continuous index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete this line and replace it with your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra resources\n",
    "To know more about `merge()` and `concat()`, please read:\n",
    "- [pandas.DataFrame.merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html?highlight=merge#pandas.DataFrame.merge)\n",
    "- [pandas.concat](https://pandas.pydata.org/docs/reference/api/pandas.concat.html?highlight=concat#pandas.concat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
